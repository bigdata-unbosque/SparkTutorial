{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark data analysis using Spark DataFrames\n",
    "Based on [this post](https://towardsdatascience.com/beginners-guide-to-pyspark-bbe3b553b79f).\n",
    "\n",
    "PySpark DataFrames cheat sheet [here](https://www.datacamp.com/blog/pyspark-cheat-sheet-spark-dataframes-in-python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import col, lit, countDistinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entry point for working with RDD\n",
    "sc = SparkContext(appName = \"pyspark-data-analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses = SparkSession.builder\\\n",
    "        .master(\"localhost\")\\\n",
    "        .appName(\"pyspark-data-analysis\")\\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and analysing data structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a csv\n",
    "df = ses.read.csv(\"./data/stocks_price_final.csv\", sep = \",\", header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the data type?\n",
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting number of records\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing columns and data types identified\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the schema to be used for the RRD during file loading\n",
    "schema = [\n",
    "    StructField('_c0', IntegerType(), True),\n",
    "    StructField('symbol', StringType(), True),\n",
    "    StructField('date', DateType(), True),\n",
    "    StructField('open', DoubleType(), True),\n",
    "    StructField('high', DoubleType(), True),\n",
    "    StructField('low', DoubleType(), True),\n",
    "    StructField('close', DoubleType(), True),\n",
    "    StructField('volume', IntegerType(), True),\n",
    "    StructField('adjusted', DoubleType(), True),\n",
    "    StructField('market.cap', StringType(), True),\n",
    "    StructField('sector', StringType(), True),\n",
    "    StructField('industry', StringType(), True),\n",
    "    StructField('exchange', StringType(), True),\n",
    "]\n",
    "\n",
    "structure = StructType(fields = schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading a csv specifying schema\n",
    "df = ses.read.csv(\"./data/stocks_price_final.csv\", sep = \",\", header = True, schema = structure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing columns and data types identified, you can also use .schema, .dtypes, .columns\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the first 20 records, you can also use .take(n), .head(n), .first()\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying and visualizing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtering data\n",
    "# Transforming to pandas is important for visualization purposes using matplotlib\n",
    "TSLA = df.filter(col(\"symbol\") == lit(\"TSLA\")).toPandas()\n",
    "GME = df.filter(col(\"symbol\") == lit(\"GME\")).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the data type?\n",
    "type(TSLA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, sharex = True, figsize = (30, 15))\n",
    "axes[0].plot(TSLA[\"date\"], TSLA[\"high\"], label = \"TSLA highest price\")\n",
    "axes[0].plot(TSLA[\"date\"], TSLA[\"low\"], label = \"TSLA lowest price\")\n",
    "axes[1].plot(GME[\"date\"], GME[\"high\"], label = \"GME highest price\")\n",
    "axes[1].plot(GME[\"date\"], GME[\"low\"], label = \"GME lowest price\")\n",
    "axes[0].set_title(\"Stock price time series for TSLA and GME\")\n",
    "axes[0].set_ylabel(\"Price\")\n",
    "axes[1].set_ylabel(\"Price\")\n",
    "plt.xlabel(\"Date\")\n",
    "axes[0].grid()\n",
    "axes[1].grid()\n",
    "axes[0].legend()\n",
    "axes[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncomp_by_sector = df.select([\"symbol\", \"sector\"]).groupBy(\"sector\").agg(countDistinct(\"symbol\").alias(\"n_companies\")).orderBy(col(\"n_companies\")).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15, 10))\n",
    "plt.barh(ncomp_by_sector[\"sector\"], ncomp_by_sector[\"n_companies\"])\n",
    "plt.title(\"Number of companies by sector\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Storing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Storing data in JSON format\n",
    "df.filter(col(\"symbol\") == lit(\"TSLA\")).select([\"date\", \"high\", \"low\"]).write.save(\"./data/TSLA_timeseries\", format = \"csv\", header = \"true\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stoping Spark context and session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ses.stop()\n",
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
